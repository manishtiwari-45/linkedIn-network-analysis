{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b189e57",
   "metadata": {},
   "source": [
    "# LinkedIn Data Cleaning\n",
    "\n",
    "## Objective:\n",
    "This notebook aims to process and analyze LinkedIn data to extract a clean network representation of student connections. Below are the key steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65993dd9",
   "metadata": {},
   "source": [
    "<h3>1. Data Ingestion & Conversion</h3>\n",
    "As some files were in .xlsx format, so changed them to .csv\n",
    "\n",
    "<h3>2. LinkedIn Data Extraction</h3>\n",
    "Read and parse the LinkedIn connection CSV files.\n",
    "Extract user connection pairs (edges) from the dataset.\n",
    "\n",
    "<h3>3. Data Cleaning & Graph Construction</h3>\n",
    "Build an adjacency list to represent the connections as a graph.\n",
    "Remove invalid or duplicate entries.\n",
    "\n",
    "<h3>4. Graph Summarization</h3>\n",
    "Use the First Year Batch List (All.csv) to provide summaries:\n",
    "Number of valid students.\n",
    "Connection patterns within the batch.\n",
    "Disconnected or isolated nodes.\n",
    "\n",
    "<h3>5. Output & Export</h3>\n",
    "Save the cleaned graph data as a .json file for downstream usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd283172",
   "metadata": {},
   "source": [
    "# Manual Work\n",
    "- Some students submitted their CSV files with file names that do not match their LinkedIn profile names so manual cleaning of file names was needed to ensure accurate mapping with LinkedIn profiles.\n",
    "- Extracted one zip file.\n",
    "- some students have submitted multiple file, so collected main copy of file.\n",
    "- Deleted and improved mannually some more necessary changes.\n",
    "\n",
    "- Student names = \"Aman Adarsh\", \"Samina Sultana\" and \"Sneha Shaw\" have submitted two files, so deleted them.\n",
    "\n",
    "- some names of student did not come as expected like for \"Anand Kumar Pandey\" it comes \"Anand Pandey\" which mismatches in actual connection name, So changes their name mannually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5ad43f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports required package and dependancies.\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc230c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: Aaditya_Raj - Aaditya Raj.csv -> Aaditya Raj.csv\n",
      "Processed: Abhishek_Singh - Abhishek Singh.csv -> Abhishek Singh.csv\n",
      "Processed: Aditya_Singh - Aditya NO-LASTNAME.csv -> Aditya No Lastname.csv\n",
      "Processed: Afzal_Raza - Afzl Raza.csv -> Afzl Raza.csv\n",
      "Processed: Ajay Jatav Connections-1 - Ajay Jatav.csv -> Ajay Jatav.csv\n",
      "Processed: Ajit_Yadav - Ajit Yadav.csv -> Ajit Yadav.csv\n",
      "Processed: Akanksha_Kushwaha - Akanksha.csv -> Akanksha.csv\n",
      "Processed: Alok_raj - Alok Raj.csv -> Alok Raj.csv\n",
      "Processed: Aman_ Adarsh.csv -> Aman Adarsh.csv\n",
      "Processed: Aman_Singh - Aman Singh.csv -> Aman Singh.csv\n",
      "Processed: amit_kumar - Amit Kumar.csv -> Amit Kumar.csv\n",
      "Processed: Anamika_Kumari - Anamika Kumari.csv -> Anamika Kumari.csv\n",
      "Processed: Anand_Pandey - Anand Pandey.csv -> Anand Pandey.csv\n",
      "Processed: Anoop_Kumar - ANOOP KUMAR.csv -> Anoop Kumar.csv\n",
      "Processed: Anshu_Kumar - Anshu Kumar.csv -> Anshu Kumar.csv\n",
      "Processed: Anuradha_Tiwari - Anuradha Tiwari.csv -> Anuradha Tiwari.csv\n",
      "Processed: Anushri_Mishra - Anushri Mishra.csv -> Anushri Mishra.csv\n",
      "Processed: Aradhya_Patel - Aradhya Patel.csv -> Aradhya Patel.csv\n",
      "Processed: Arjun Kadam - Arjun Kadam.csv -> Arjun Kadam.csv\n",
      "Processed: Arpita_Tripathi - Arpita Tripathi.csv -> Arpita Tripathi.csv\n",
      "Processed: Arun_Singh - ARUN KUMAR.csv -> Arun Kumar.csv\n",
      "Processed: aryan_saini - Aryan Saini.csv -> Aryan Saini.csv\n",
      "Processed: Ashwin_Yadav - Ashwin Yadav.xlsx -> Ashwin Yadav.csv\n",
      "Processed: Ayush_Kumar - Ayush Kumar.csv -> Ayush Kumar.csv\n",
      "Processed: Ayush_yadav - AYUSH YADAV.csv -> Ayush Yadav.csv\n",
      "Processed: Bhagwati_Chouhan - Bhagwati NO-LASTNAME.csv -> Bhagwati No Lastname.csv\n",
      "Processed: Bhaskar_mahato - Bhaskar Mahato.csv -> Bhaskar Mahato.csv\n",
      "Processed: ByagariPraveen_Kumar - Byagari Kumar.csv -> Byagari Kumar.csv\n",
      "Processed: Challa_Trivedh_Kumar - CHALLA TRIVEDH KUMAR.csv -> Challa Trivedh Kumar.csv\n",
      "Processed: CHANDAN_GIRI - Chandan Giri.csv -> Chandan Giri.csv\n",
      "Processed: Chiranjeet_Biswas - Chiranjeet Biswas.csv -> Chiranjeet Biswas.csv\n",
      "Processed: Cleaned_Connections - Bhagwan Singh Rawat.csv -> Bhagwan Singh Rawat.csv\n",
      "Processed: Connection - VISHAL KUMAR.csv -> Vishal Kumar.csv\n",
      "Error processing connection1-1 - Aman Adarsh.csv: [WinError 183] Cannot create a file when that file already exists: 'C:\\\\Desktop\\\\MFC ass\\\\LinkedIn Data Public\\\\connection1-1 - Aman Adarsh.csv' -> 'C:\\\\Desktop\\\\MFC ass\\\\LinkedIn Data Public\\\\Aman Adarsh.csv'\n",
      "Processed: Connections - Aman Verma.csv -> Aman Verma.csv\n",
      "Processed: Connections - Anand Singh.csv -> Anand Singh.csv\n",
      "Processed: Connections - Harshit Chaturvedi.csv -> Harshit Chaturvedi.csv\n",
      "Processed: connections - N. Arun Kumar.csv -> N. Arun Kumar.csv\n",
      "Processed: Connections - Ompal Yadav.csv -> Ompal Yadav.csv\n",
      "Processed: Connections - RAVI RAJPUT.csv -> Ravi Rajput.csv\n",
      "Processed: debangsu_misra.csv - Debangsu Misra.csv -> Debangsu Misra.csv\n",
      "Processed: Dilip_Suthar - DILIP SUTHAR.csv -> Dilip Suthar.csv\n",
      "Processed: Disha_Sahu - Disha Sahu.csv -> Disha Sahu.csv\n",
      "Processed: Divyanshi_Rathour - Divyanshi Rathour.csv -> Divyanshi Rathour.csv\n",
      "Processed: Divyanshi_Sahu.csv - Divyanshi Sahu.csv -> Divyanshi Sahu.csv\n",
      "Processed: Ekta Kumari - Ekta Kumari.csv -> Ekta Kumari.csv\n",
      "Processed: gaurav_khainwar.csv - Gaurav Khainwar.csv -> Gaurav Khainwar.csv\n",
      "Processed: Gaurav_Rathore - Gaurav Rathore.csv -> Gaurav Rathore.csv\n",
      "Processed: Gaurav_Tiwari - GAURAV TIWARI.csv -> Gaurav Tiwari.csv\n",
      "Processed: Harisingh_Rajpoot - Harisingh Rajpoot.csv -> Harisingh Rajpoot.csv\n",
      "Processed: HimanshuKanwarChundawat - Himanshu Chundawat.csv -> Himanshu Chundawat.csv\n",
      "Processed: Himanshu_kumar - Himanshu Kumar.csv -> Himanshu Kumar.csv\n",
      "Processed: Himanshu_Srivastav - Himanshu Srivastav.csv -> Himanshu Srivastav.csv\n",
      "Processed: Hiranya_Patil - Hiranya Patil.csv -> Hiranya Patil.csv\n",
      "Processed: Ishant_Bhoyar - ISHANT BHOYAR.csv -> Ishant Bhoyar.csv\n",
      "Processed: JAMAL_AKHTAR - JAMAL AKHTAR.csv -> Jamal Akhtar.csv\n",
      "Processed: Janu_Chaudhary - Janu Chaudhary.csv -> Janu Chaudhary.csv\n",
      "Processed: KARANPAL_SINGH_RANAWAT - KARANPAL SINGH RANAWAT.csv -> Karanpal Singh Ranawat.csv\n",
      "Processed: khushi_narwariya - Khushi Narwariya.csv -> Khushi Narwariya.csv\n",
      "Processed: Kuldeep_Saraswat - Kuldeep saraswat.csv -> Kuldeep Saraswat.csv\n",
      "Processed: Lakhan_Rathore - Lakhan Rathore.csv -> Lakhan Rathore.csv\n",
      "Processed: linkedin list - Nidhi Kumari.csv -> Nidhi Kumari.csv\n",
      "Processed: linkedin_Connections - SNEHA SHAW.csv -> Sneha Shaw.csv\n",
      "Processed: Linked_in_connection - Samina Sultana.csv -> Samina Sultana.csv\n",
      "Processed: Maneesh_Sakhwar - Maneesh Sakhwar.csv -> Maneesh Sakhwar.csv\n",
      "Processed: Manish_Tiwari - MANISH KUMAR TIWARI.csv -> Manish Kumar Tiwari.csv\n",
      "Processed: Manoj K. Connections - MANOJ KHARKAR.xlsx -> Manoj Kharkar.csv\n",
      "Processed: Manoj_Dewda - Manoj Dewda.xlsx -> Manoj Dewda.csv\n",
      "Processed: Mausam_kumari - Mausam kumari.csv -> Mausam Kumari.csv\n",
      "Processed: Mayank_Raj - Mayank Raj.csv -> Mayank Raj.csv\n",
      "Processed: Mehtab_Alam - MEHTAB ALAM.csv -> Mehtab Alam.csv\n",
      "Processed: Mohd_Monis - Monis.csv -> Monis.csv\n",
      "Processed: Mohit_Sharma - Mohit Sharma.csv -> Mohit Sharma.csv\n",
      "Processed: Monu_Rajpoot - Monu Rajpoot.csv -> Monu Rajpoot.csv\n",
      "Processed: Naman_Damami - Naman Damami.csv -> Naman Damami.csv\n",
      "Processed: Neeraj_Parmar - NEERAJ PARMAR.csv -> Neeraj Parmar.csv\n",
      "Processed: Nikhil_Chaurasiya - Nikhil Chaurasiya.csv -> Nikhil Chaurasiya.csv\n",
      "Processed: Nirmal LinkdIn Connections - NIRMAL MEWADA.csv -> Nirmal Mewada.csv\n",
      "Processed: Pawan_Kushwah - Pawan Kushwah.csv -> Pawan Kushwah.csv\n",
      "Processed: Pinky_Rana - Pinky Rana.csv -> Pinky Rana.csv\n",
      "Processed: Pooran_Singh - POORAN SINGH.csv -> Pooran Singh.csv\n",
      "Processed: Prabhat_Patidar - prabhat patidar.csv -> Prabhat Patidar.csv\n",
      "Processed: Prachi_Dhakad - PRACHI DHAKAD.csv -> Prachi Dhakad.csv\n",
      "Processed: Pragati_Chauhan - Pragati Chauhan.csv -> Pragati Chauhan.csv\n",
      "Processed: Pranjal_Dubey - Pranjal Dubey.csv -> Pranjal Dubey.csv\n",
      "Processed: Prem kumar.csv -> Prem Kumar.csv\n",
      "Processed: Prerana_Rajnag - PRERANA RAJNAG.csv -> Prerana Rajnag.csv\n",
      "Processed: Priyadarshi_Kumar - Priyadarshi Kumar.csv -> Priyadarshi Kumar.csv\n",
      "Processed: Priya_saini - Priya Saini.csv -> Priya Saini.csv\n",
      "Processed: Pushpraj_Singh.csv - Pushpraj Singh.csv -> Pushpraj Singh.csv\n",
      "Processed: Rahul_Kumar - Rahul Kumar.csv -> Rahul Kumar.csv\n",
      "Processed: Rahul_Kumar_Verma - Rahul Verma.csv -> Rahul Verma.csv\n",
      "Processed: Rajiv_Kumar - RAJIV KUMAR.csv -> Rajiv Kumar.csv\n",
      "Processed: Ramraj_Nagar - Ramraj Nagar.csv -> Ramraj Nagar.csv\n",
      "Processed: Rani_Kumari - Rani Kumari.csv -> Rani Kumari.csv\n",
      "Processed: Ranjeet_Kumar_Yadav - Ranjeet Yadav.csv -> Ranjeet Yadav.csv\n",
      "Processed: Ravi_Mourya - Ravi Mourya.csv -> Ravi Mourya.csv\n",
      "Processed: Ritik_Singh - ritik singh.csv -> Ritik Singh.csv\n",
      "Processed: Rohit_kumar - ROHIT KUMAR.csv -> Rohit Kumar.csv\n",
      "Processed: Rohit_Malviya - Rohit Malviya.csv -> Rohit Malviya.csv\n",
      "Processed: Sajan_Kumar - SAJAN KUMAR.csv -> Sajan Kumar.csv\n",
      "Error processing Samina_Sultana.csv: [WinError 183] Cannot create a file when that file already exists: 'C:\\\\Desktop\\\\MFC ass\\\\LinkedIn Data Public\\\\Samina_Sultana.csv' -> 'C:\\\\Desktop\\\\MFC ass\\\\LinkedIn Data Public\\\\Samina Sultana.csv'\n",
      "Processed: Sandeep_kumar - Sandeep Kumar.csv -> Sandeep Kumar.csv\n",
      "Processed: Sandhya_Kaushal - Sandhya Kaushal.csv -> Sandhya Kaushal.csv\n",
      "Processed: Sandhya_Parmar - Sandhya Parmar.csv -> Sandhya Parmar.csv\n",
      "Processed: Sarthaksuman_Mishra - Sarthak Mishra.csv -> Sarthak Mishra.csv\n",
      "Processed: Satish_Mahto - Satish Mahto.csv -> Satish Mahto.csv\n",
      "Processed: Sauhard_kumar - Sauhard kumar.csv -> Sauhard Kumar.csv\n",
      "Processed: Saurabh_Bisht - Saurabh Bisht.csv -> Saurabh Bisht.csv\n",
      "Processed: Shahid_Ansari - Shahid Ansari.csv -> Shahid Ansari.csv\n",
      "Processed: Shilpi_Shaw - Shilpi Shaw.csv -> Shilpi Shaw.csv\n",
      "Processed: Shivam_Shukla.csv -> Shivam Shukla.csv\n",
      "Processed: Shivang_Dubey - Shivang Dubey.csv -> Shivang Dubey.csv\n",
      "Processed: Shlok_Gupta - Shlok Gupta.csv -> Shlok Gupta.csv\n",
      "Processed: Shubham Kumar - Shubham Kumar.csv -> Shubham Kumar.csv\n",
      "Processed: Shubham_Kang - Shubham Kang.csv -> Shubham Kang.csv\n",
      "Error processing Sneha_Shaw.csv: [WinError 183] Cannot create a file when that file already exists: 'C:\\\\Desktop\\\\MFC ass\\\\LinkedIn Data Public\\\\Sneha_Shaw.csv' -> 'C:\\\\Desktop\\\\MFC ass\\\\LinkedIn Data Public\\\\Sneha Shaw.csv'\n",
      "Processed: Sunny_Kumar - Sunny Kumar.csv -> Sunny Kumar.csv\n",
      "Processed: Suyash_Yadav - Suyash Yadav.csv -> Suyash Yadav.csv\n",
      "Processed: Swati_Kumari - Swati kumari.csv -> Swati Kumari.csv\n",
      "Processed: Ujjval_Baijal - Ujjval Baijal.csv -> Ujjval Baijal.csv\n",
      "Processed: Uppara Sai_Maithreyi - UPPARA MAITHREYI.csv -> Uppara Maithreyi.csv\n",
      "Processed: Vinay_Gupta - VINAY GUPTA.csv -> Vinay Gupta.csv\n",
      "Processed: Vinay_Kumar - VINAY KUMAR.csv -> Vinay Kumar.csv\n",
      "Processed: Vishal_Bhardwaj - VISHAL BHARDWAJ.csv -> Vishal Bhardwaj.csv\n",
      "Processed: Vivek_kumar - VIVEK KUMAR.csv -> Vivek Kumar.csv\n",
      "Error processing Vivek_Singh - Vivek Kumar.csv: [WinError 183] Cannot create a file when that file already exists: 'C:\\\\Desktop\\\\MFC ass\\\\LinkedIn Data Public\\\\Vivek_Singh - Vivek Kumar.csv' -> 'C:\\\\Desktop\\\\MFC ass\\\\LinkedIn Data Public\\\\Vivek Kumar.csv'\n",
      "Processed: YuvrajSingh_Bhati - Yuvraj Bhati.csv -> Yuvraj Bhati.csv\n",
      "Processed: Yuvraj_Chirag - Yuvraj Chirag.xlsx -> Yuvraj Chirag.csv\n",
      "All files renamed and converted successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "folder_path = r'C:\\Desktop\\MFC ass\\LinkedIn Data Public'\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(('.csv', '.xlsx')):\n",
    "        old_file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        name_part = filename.rsplit('.', 1)[0]\n",
    "        name_part = name_part.split('-', 1)[-1] if '-' in name_part else name_part\n",
    "        name_part = re.sub(r'^[^a-zA-Z]+', '', name_part).strip()\n",
    "\n",
    "        name_clean = name_part.replace('_', ' ').replace('-', ' ')\n",
    "        name_clean = ' '.join(word.capitalize() for word in name_clean.split())\n",
    "\n",
    "        new_filename = name_clean + '.csv'\n",
    "        new_file_path = os.path.join(folder_path, new_filename)\n",
    "\n",
    "        try:\n",
    "            if filename.endswith('.xlsx'):\n",
    "                df = pd.read_excel(old_file_path)\n",
    "                df.to_csv(new_file_path, index=False)\n",
    "                os.remove(old_file_path)\n",
    "            else:\n",
    "                os.rename(old_file_path, new_file_path)\n",
    "\n",
    "            print(f\"Processed: {filename} -> {new_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "print(\"All files renamed and converted successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eebd957",
   "metadata": {},
   "source": [
    "### ✅ Cleaned Pooran Singh CSV File Separately\n",
    "\n",
    "I have cleaned the **Pooran Singh** data file which had the following issues:\n",
    "- Merged first and last names in a single column\n",
    "- Missing or misaligned columns\n",
    "- Extra/missing name parts\n",
    "\n",
    "Now the file has:\n",
    "- Properly separated **First Name**, **Last Name**, and **Company** columns\n",
    "- Handled edge cases like middle names or missing values\n",
    "- Saved as **Pooran_Singh.csv** in a consistent format\n",
    "\n",
    "####  Python Code Used:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"LinkedIn Data Public\\Pooran Singh.csv\", sep=\"\\t\", engine='python')\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "cleaned_data = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    first = row['First Name'].strip()\n",
    "    last = row['Last Name'].strip()\n",
    "    company = row['Company'].strip() if 'Company' in row else ''\n",
    "    cleaned_data.append([first, last, company])\n",
    "\n",
    "cleaned_df = pd.DataFrame(cleaned_data, columns=['First Name', 'Last Name', 'Company'])\n",
    "cleaned_df.to_csv(\"Pooran_Singh.csv\", index=False)\n",
    "\n",
    "print(\"Data cleaning complete! The cleaned data is saved as 'Pooran_Singh.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "358af8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files cleaned successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder_path = r\"C:\\Desktop\\MFC ass\\LinkedIn Data Public\"\n",
    "\n",
    "def clean_text(text, allow_digits=False):\n",
    "    cleaned = \"\"\n",
    "    for char in text:\n",
    "        if char.isalpha() or char.isspace() or (allow_digits and char.isdigit()):\n",
    "            cleaned += char\n",
    "    return cleaned\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        df.columns = [col.strip() for col in df.columns]\n",
    "\n",
    "        if 'First Name' in df.columns and 'Last Name' in df.columns and 'Company' in df.columns:\n",
    "            for index in df.index:\n",
    "                first = str(df.at[index, 'First Name'])\n",
    "                last = str(df.at[index, 'Last Name'])\n",
    "                company = str(df.at[index, 'Company'])\n",
    "\n",
    "                df.at[index, 'First Name'] = clean_text(first)\n",
    "                df.at[index, 'Last Name'] = clean_text(last) if last.lower() != \"nan\" else \"\"\n",
    "                df.at[index, 'Company'] = clean_text(company, allow_digits=True) if company.lower() != \"nan\" else \"\"\n",
    "\n",
    "            df.to_csv(file_path, index=False)\n",
    "print(\"All files cleaned successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00efc983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CSV files: 126\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "folder_path = r\"C:\\Desktop\\MFC ass\\LinkedIn Data Public\"\n",
    "count = 0\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".csv\"):\n",
    "        count += 1\n",
    "\n",
    "print(\"Total CSV files:\", count)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
